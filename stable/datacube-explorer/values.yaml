# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
serviceAccountName:
replicaCount: 1

image:
  registry: docker.io
  repository: opendatacube/explorer
  tag: "latest"
  pullPolicy: Always

database:
  database: datacube
  host: localhost
  port: 5432
  existingSecret: "explorer-reader"

resources:
  limits:
    cpu: "300m"
    memory: 1024Mi

annotations: {}

livenessProbe:
  httpGet:
    path: "/stac"
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 30
  timeoutSeconds: 60
  failureThreshold: 5

readinessProbe:
  httpGet:
    path: "/stac"
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 30
  timeoutSeconds: 60
  failureThreshold: 5

startupProbe:
  httpGet:
    path: "/stac"
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 30
  timeoutSeconds: 60
  failureThreshold: 5

additionalEnvironmentVars: {}

service:
  type: ClusterIP

externalPort: 80 # External port on which service listen to
internalPort: 8080 # Internal port on which pod is running and serving cubedash app

dockerArgs: ["gunicorn", "-b", "0.0.0.0:8080", "-w", "3", "--threads=2", "-k",
   "gthread", "-t", "60", "--pid", "gunicorn.pid", "--worker-tmp-dir", "/dev/shm",
   "--preload", "--config", "python:cubedash.gunicorn_config", "cubedash:app",
   "||", "true"]

updateCreationDt:
  # --- Whether to create a CronJob to automatically keep the Explorer extents tables up to date
  enabled: false
  historyLimit: 1
  # --- Allow concurrent executions of the Job
  concurrencyPolicy: Allow  # concurrent executions of a job
  # --- Default to run at 11pm Australia Eastern Daylight Time
  cron: "0 13 * * *"
  suspend: false
  backoffLimit: 0  # Number of retries
  dockerArgs:
  - "cubedash-gen"
  - "--no-init-database"
  - "--refresh-stats"
  - "--all"

additionalSettings: {}

affinity: {}

ingress:
  enabled: false
  path: "/"
  hosts:
    - ""
  annotations: {}
